{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "MOTIVATION:\n",
    "- Understand how well fitting works with a single feed fraction experiment. \n",
    "\n",
    "HYPOTHESIS:\n",
    "- Low feed fractions will be difficult to fit. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tests rely on tellurium to construct the models\n",
      "Since tellurium is not installed the tests can't be run\n",
      "If you want to run the tests, pip install tellurium first\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (pypesto.py, line 106)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3579\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\n\u001b[0;31m    from polypesto.core.pypesto import create_problem_set, load_pypesto_problem\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m/PolyPESTO/polypesto/core/pypesto.py:106\u001b[0;36m\u001b[0m\n\u001b[0;31m    def visualize_parameter_cis()\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# import matplotlib\n",
    "\n",
    "# matplotlib.use(\"webagg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from polypesto.models.CRP2 import ReversibleCPE as Model\n",
    "from polypesto.core.params import ParameterGroup\n",
    "import polypesto.core.petab as pet\n",
    "from polypesto.core.pypesto import create_problem_set, load_pypesto_problem\n",
    "from polypesto.core.params import ParameterSet, ParameterGroup\n",
    "from polypesto.utils.plot import plot_all_measurements\n",
    "\n",
    "import amici\n",
    "logger = amici.logging.get_logger()\n",
    "amici.logging.set_log_level(logger, 1)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = \"/PolyPESTO/experiments/reversible_cpe/single_rxn/analysis.ipynb\"\n",
    "DIR_NAME = os.path.basename(os.path.dirname(__file__))\n",
    "DATA_DIR = os.path.join(os.path.dirname(__file__), \"data\")\n",
    "\n",
    "\n",
    "# ************** Define parameters **************\n",
    "def parameters() -> ParameterGroup:\n",
    "    rA = [0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "    rB = [0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "    KAA = [0, 0.25, 0.5, 0.75]\n",
    "    # rA = [3]\n",
    "    # rB = [10]\n",
    "\n",
    "    pg = ParameterGroup(DIR_NAME, {})\n",
    "    for _rA in rA:\n",
    "        for _rB in rB:\n",
    "            for _KAA in KAA:\n",
    "                pg.lazy_add({\"rA\": _rA, \"rB\": _rB, \"KAA\": _KAA})\n",
    "\n",
    "    return pg\n",
    "\n",
    "\n",
    "# ************** Define experiments **************\n",
    "# experimental conditions, observables, and fit parameters\n",
    "def experiment(t_eval, fA0s, cM0s) -> Tuple[str, pet.PetabData]:\n",
    "\n",
    "    dir = os.path.join(DATA_DIR, f\"fA0_{fA0s[0]:.2f}\")\n",
    "\n",
    "    # Define fitting parameters\n",
    "    params_dict = Model.get_default_fit_params()\n",
    "    params_dict[\"KAA\"].estimate = True\n",
    "    param_df = pet.define_parameters(params_dict)\n",
    "\n",
    "    # Define experimental conditions\n",
    "    cond_df = Model.create_conditions(fA0s, cM0s)\n",
    "    obs_df = Model.get_default_observables()\n",
    "    empty_meas_df = pet.define_empty_measurements(obs_df, cond_df, t_eval)\n",
    "\n",
    "    return dir, pet.PetabData(\n",
    "        obs_df=obs_df, cond_df=cond_df, param_df=param_df, meas_df=empty_meas_df\n",
    "    )\n",
    "\n",
    "\n",
    "# ************** Define experiments **************\n",
    "t_eval = np.arange(0, 1, 0.1, dtype=float)\n",
    "fA0s = np.array([[0.50]])\n",
    "cM0s = np.array([[1.0]])\n",
    "\n",
    "force_compile = True\n",
    "for fA0, cM0 in zip(fA0s, cM0s):\n",
    "\n",
    "    # print(fA0, cM0)\n",
    "    dir, data = experiment(t_eval, fA0, cM0)\n",
    "    pg = parameters()\n",
    "    print(pg)\n",
    "    yaml_paths = create_problem_set(\n",
    "        Model, parameters(), data, dir, force_compile=force_compile\n",
    "    )\n",
    "    force_compile = False\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = yaml_paths[\"p_021\"]\n",
    "importer, problem = load_pypesto_problem(yaml_path=yaml_path, model_name=Model.name)\n",
    "\n",
    "plot_all_measurements(\n",
    "    importer.petab_problem.measurement_df,\n",
    "    # group_by=C.SIMULATION_CONDITION_ID,\n",
    "    group_by=pet.C.OBSERVABLE_ID,\n",
    "    format_axes_kwargs={\n",
    "        \"set_xlabel\": \"Total Conversion\",\n",
    "        \"set_ylabel\": \"Monomer Conversion\",\n",
    "        # \"set_xlim\": (0, 1),\n",
    "        # \"set_ylim\": (0, 1),\n",
    "    },\n",
    "    plot_style=\"both\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypesto\n",
    "import pypesto.optimize as optimize\n",
    "import pypesto.petab\n",
    "import pypesto.sample as sample\n",
    "import pypesto.visualize as visualize\n",
    "\n",
    "optimizer = optimize.ScipyOptimizer()  # method=\"Nelder-Mead\")  # method=\"Nelder-Mead\")\n",
    "# optimizer = optimize.PyswarmOptimizer()\n",
    "history_options = pypesto.HistoryOptions(\n",
    "    trace_record=True,  # storage_file=\"history_{id}.csv\"\n",
    ")\n",
    "engine = pypesto.engine.MultiProcessEngine()\n",
    "n_starts = 1000\n",
    "\n",
    "# run optimization of problem 1\n",
    "import amici\n",
    "\n",
    "# problem.startpoint_method = pypesto.startpoint.LatinHypercubeStartpoints()\n",
    "# problem.objective.amici_solver.setSensitivityMethod(amici.SensitivityMethod.none)\n",
    "# problem.objective.amici_solver.setSensitivityOrder(amici.SensitivityOrder.first)\n",
    "# problem.objective.amici_solver.setMaxStepSize(1e-3)\n",
    "# problem.objective.amici_model.setAlwaysCheckFinite(True)\n",
    "# problem.objective.amici_solver.setSensitivityOrder(1)\n",
    "# problem.objective.amici_solver.\n",
    "# problem.objective.amici_solver.setSensitivityOrder(amici.SensitivityOrder.first)\n",
    "optimizer = optimize.ScipyOptimizer(method=\"Nelder-Mead\")  # method=\"Nelder-Mead\")\n",
    "history_options = pypesto.HistoryOptions(\n",
    "    trace_record=True,  # storage_file=\"history_{id}.csv\"\n",
    ")\n",
    "# engine = pypesto.engine.MultiProcessEngine()\n",
    "engine = pypesto.engine.SingleCoreEngine()\n",
    "n_starts = 100\n",
    "\n",
    "# problem.objective.amici_solver.setMaxStepSize(1e-3)\n",
    "result = optimize.minimize(\n",
    "    problem=problem,\n",
    "    optimizer=optimizer,\n",
    "    n_starts=n_starts,\n",
    "    engine=engine,\n",
    "    history_options=history_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.optimization_scatter(result=result, show_bounds=True)\n",
    "ax = visualize.waterfall(result)\n",
    "ax = visualize.parameters(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = sample.AdaptiveParallelTemperingSampler(\n",
    "    internal_sampler=sample.AdaptiveMetropolisSampler(),\n",
    "    n_chains=5,\n",
    "    # betas=[1, 0.5, 0.1, 0.05],\n",
    "    # options=dict(max_temp=10),\n",
    ")\n",
    "# sampler = sample.AdaptiveMetropolisSampler()\n",
    "# sampler = sample.MetropolisSampler()\n",
    "# problem.objective.amici_solver.setMaxStepSize(1e-3)\n",
    "n_samples = 100000\n",
    "result = sample.sample(\n",
    "    problem,\n",
    "    n_samples=n_samples,\n",
    "    sampler=sampler,\n",
    "    # x0=result.optimize_result.list[0][\"x\"][0:2],\n",
    "    # x0=np.array([0, 0]),\n",
    "    filename=None,\n",
    "    result=result,\n",
    ")\n",
    "elapsed_time = result.sample_result.time\n",
    "print(f\"Elapsed time: {round(elapsed_time,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sample_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.sampling_fval_traces(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.sampling_parameter_traces(result, use_problem_bounds=True, size=(12, 5))\n",
    "\n",
    "\n",
    "# pg = pg.by_id(\"p2\").to_dict()\n",
    "p = parameters().by_id(\"p_021\").to_dict()\n",
    "ax[0][0].plot([0, n_samples], np.log10([p[\"rA\"], p[\"rA\"]]), \"r--\", linewidth=4)\n",
    "ax[0][1].plot([0, n_samples], np.log10([p[\"rB\"], p[\"rB\"]]), \"r--\", linewidth=4)\n",
    "# ax[0][0].plot([0, n_samples], ([p[\"rA\"], p[\"rA\"]]), \"r--\")\n",
    "# ax[0][1].plot([0, n_samples], ([p[\"rB\"], p[\"rB\"]]), \"r--\")\n",
    "# ax[1][0].plot([0, n_samples], [p[\"KAA\"], p[\"KAA\"]], \"r--\")\n",
    "# ax[1][1].plot([0, n_samples], [p[\"KBA\"], p[\"KBA\"]], \"r--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.sampling_parameter_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesto.C import AMICI_STATUS, AMICI_T, AMICI_X, AMICI_Y\n",
    "from pypesto.predict import AmiciPredictor\n",
    "\n",
    "\n",
    "# This post_processor will transform the output of the simulation tool\n",
    "# such that the output is compatible with the next steps.\n",
    "def post_processor(amici_outputs, output_type, output_ids):\n",
    "    outputs = [\n",
    "        (\n",
    "            amici_output[output_type]\n",
    "            if amici_output[AMICI_STATUS] == 0\n",
    "            else np.full((len(amici_output[AMICI_T]), len(output_ids)), np.nan)\n",
    "        )\n",
    "        for amici_output in amici_outputs\n",
    "    ]\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# Setup post-processors for both states and observables.\n",
    "from functools import partial\n",
    "\n",
    "amici_objective = result.problem.objective\n",
    "state_ids = amici_objective.amici_model.getStateIds()\n",
    "observable_ids = amici_objective.amici_model.getObservableIds()\n",
    "post_processor_x = partial(\n",
    "    post_processor,\n",
    "    output_type=AMICI_X,\n",
    "    output_ids=state_ids,\n",
    ")\n",
    "post_processor_y = partial(\n",
    "    post_processor,\n",
    "    output_type=AMICI_Y,\n",
    "    output_ids=observable_ids,\n",
    ")\n",
    "\n",
    "# Create pyPESTO predictors for states and observables\n",
    "predictor_x = AmiciPredictor(\n",
    "    amici_objective,\n",
    "    post_processor=post_processor_x,\n",
    "    output_ids=state_ids,\n",
    ")\n",
    "predictor_y = AmiciPredictor(\n",
    "    amici_objective,\n",
    "    post_processor=post_processor_y,\n",
    "    output_ids=observable_ids,\n",
    ")\n",
    "\n",
    "from pypesto.C import EnsembleType\n",
    "from pypesto.ensemble import Ensemble\n",
    "\n",
    "# corresponds to only the estimated parameters\n",
    "x_names = result.problem.get_reduced_vector(result.problem.x_names)\n",
    "\n",
    "# Create the ensemble with the MCMC chain from parallel tempering with the real temperature.\n",
    "ensemble = Ensemble.from_sample(\n",
    "    result,\n",
    "    chain_slice=slice(\n",
    "        None, None, 5\n",
    "    ),  # Optional argument: only use every fifth vector in the chain.\n",
    "    x_names=x_names,\n",
    "    ensemble_type=EnsembleType.sample,\n",
    "    lower_bound=result.problem.lb,\n",
    "    upper_bound=result.problem.ub,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sample_result.betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_1d_marginals(\n",
    "        result,\n",
    "        i_chain=i_chain,\n",
    "        suptitle=f\"Chain: {i_chain}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesto.engine import MultiProcessEngine\n",
    "\n",
    "engine = MultiProcessEngine()\n",
    "\n",
    "ensemble_prediction = ensemble.predict(\n",
    "    predictor_x, prediction_id=AMICI_X, engine=engine\n",
    ")\n",
    "from pypesto.C import CONDITION, OUTPUT\n",
    "\n",
    "credibility_interval_levels = [90, 95, 99]\n",
    "\n",
    "ax = visualize.sampling_prediction_trajectories(\n",
    "    ensemble_prediction,\n",
    "    levels=credibility_interval_levels,\n",
    "    size=(10, 5),\n",
    "    # labels={\"A\": \"state_A\", \"condition_0\": \"cond_0\"},\n",
    "    axis_label_padding=60,\n",
    "    groupby=CONDITION,\n",
    "    # condition_ids=[\"condition_0\", \"condition_1\", \"condition_2\"],  # `None` for all conditions\n",
    "    # output_ids=[\"A\", \"B\"],  # `None` for all outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petab_problem = importer.petab_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_measurement_fit(petab_problem, engine):\n",
    "\n",
    "    mdf = petab_problem.measurement_df\n",
    "    # Create a custom objective with new output timepoints.\n",
    "    conditions = mdf[pet.C.SIMULATION_CONDITION_ID].unique()\n",
    "    timepoints = [\n",
    "        mdf[mdf[pet.C.SIMULATION_CONDITION_ID] == c][pet.C.TIME].unique()\n",
    "        for c in conditions\n",
    "    ]\n",
    "    amici_objective_custom = amici_objective.set_custom_timepoints(\n",
    "        timepoints=timepoints\n",
    "    )\n",
    "\n",
    "    # Create an observable predictor with the custom objective.\n",
    "    predictor_y_custom = AmiciPredictor(\n",
    "        amici_objective_custom,\n",
    "        post_processor=post_processor_y,\n",
    "        output_ids=observable_ids,\n",
    "        condition_ids=[edata.id for edata in amici_objective_custom.edatas],\n",
    "    )\n",
    "\n",
    "    # Predict then plot.\n",
    "    ensemble_prediction = ensemble.predict(\n",
    "        predictor_y_custom, prediction_id=AMICI_Y, engine=engine\n",
    "    )\n",
    "\n",
    "    ax = visualize.sampling_prediction_trajectories(\n",
    "        ensemble_prediction,\n",
    "        levels=credibility_interval_levels,\n",
    "        groupby=CONDITION,\n",
    "        # measurement_df=mdf,\n",
    "        size=(12, 6),\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# ax[0][0].set_title('')\n",
    "# ax[1][0].set_title('')\n",
    "# ax[0][1].set_title('')\n",
    "# # ax[1][1].set_title('')\n",
    "# ax[0][0].set_ylim([-0.1, 2.1])\n",
    "# ax[1][0].set_ylim([-0.1, 2.1])\n",
    "# ax[0][1].set_ylim([-0.1, 2.1])\n",
    "# ax[1][1].set_ylim([-0.1, 2.1])\n",
    "\n",
    "ax = show_measurement_fit(petab_problem, engine)\n",
    "plt.tight_layout()\n",
    "fig = ax[0][0].get_figure()\n",
    "fig.savefig(\"FRP2_measurement_fit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sampling_results(result, petab_problem, engine=None):\n",
    "    \"\"\"\n",
    "    Visualize how sampled parameters predict the data with credibility intervals.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    result : pypesto.Result\n",
    "        PyPESTO result object containing sampling results\n",
    "    petab_problem : petab.Problem\n",
    "        PEtab problem definition\n",
    "    engine : pypesto.Engine, optional\n",
    "        Engine for parallel computation\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ax : matplotlib.axes\n",
    "        The axes with the plotted results\n",
    "    \"\"\"\n",
    "    # Create an ensemble from the sampling results\n",
    "    # Skip burn-in period (first 20% of samples)\n",
    "    samples = result.sample_result.trace_x[0]\n",
    "    burnin = int(len(samples) * 0.2)\n",
    "    samples_subset = samples[burnin::10]  # Take every 10th sample to reduce computation\n",
    "    print(samples_subset)\n",
    "\n",
    "    # Create the ensemble\n",
    "    ensemble = pypesto.ensemble.Ensemble(samples_subset)\n",
    "    print(ensemble)\n",
    "    # Get measurement data frame\n",
    "    mdf = petab_problem.measurement_df\n",
    "\n",
    "    # Extract unique conditions and timepoints\n",
    "    conditions = mdf[pet.C.SIMULATION_CONDITION_ID].unique()\n",
    "    timepoints = [\n",
    "        mdf[mdf[pet.C.SIMULATION_CONDITION_ID] == c][pet.C.TIME].unique()\n",
    "        for c in conditions\n",
    "    ]\n",
    "    print(timepoints)\n",
    "    # Create custom objective with these timepoints\n",
    "    amici_objective_custom = result.problem.objective.set_custom_timepoints(\n",
    "        timepoints=timepoints\n",
    "    )\n",
    "\n",
    "    # Define the observable IDs (based on your model)\n",
    "    observable_ids = petab_problem.observable_df.index.tolist()\n",
    "\n",
    "    # Create predictor with the custom objective\n",
    "    predictor_y_custom = pypesto.predict.AmiciPredictor(\n",
    "        amici_objective_custom,\n",
    "        # Use appropriate post-processor for your model\n",
    "        condition_ids=[edata.id for edata in amici_objective_custom.edatas],\n",
    "        output_ids=observable_ids,\n",
    "    )\n",
    "\n",
    "    # Define credibility interval levels\n",
    "    credibility_interval_levels = [0.5, 0.95]  # 50% and 95% CI\n",
    "\n",
    "    # Predict then plot\n",
    "    ensemble_prediction = ensemble.predict(\n",
    "        predictor_y_custom,  # prediction_id=\"y_model\", engine=engine\n",
    "    )\n",
    "\n",
    "    # Create visualizations\n",
    "    ax = pypesto.visualize.sampling_prediction_trajectories(\n",
    "        ensemble_prediction,\n",
    "        levels=credibility_interval_levels,\n",
    "        groupby=\"condition\",\n",
    "        measurement_df=mdf,  # Include measurements\n",
    "        size=(12, 6),\n",
    "    )\n",
    "\n",
    "    # Customize the plot if needed\n",
    "    for row in ax:\n",
    "        for subplot in row:\n",
    "            subplot.set_ylim([-0.1, 2.1])  # Adjust based on your data range\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "petab_problem = importer.petab_problem\n",
    "visualize_sampling_results(result, petab_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = result.sample_result.trace_x[0]\n",
    "samples[10::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
